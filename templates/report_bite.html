{% extends 'base.html' %}
  {% block title %}Report a Bite - DengueTect{% endblock %}
  {% block content %}
    <h2 class="page-title">Report a Bite</h2>

    <div class="card soft">
      <h3 class="card-title">Upload Bite Photo</h3>
      <p class="muted">Take or upload a clear photo of the suspected mosquito bite for AI analysis</p>

      <div id="dropzone" class="dropzone" style="position:relative">
        <div class="dropzone-inner">
          <i class="bi bi-camera2 dropzone-icon"></i>
          <p class="muted">No image selected</p>
          <small class="muted">Drag & drop a photo here</small>
        </div>
        <img id="preview-img" class="dropzone-preview hidden" alt="Preview" />
        <!-- Inline camera lives inside the dropzone so no extra frame -->
        <video id="cameraVideo" class="dropzone-video hidden" autoplay playsinline muted></video>
        <div id="colorIndicator" class="color-indicator muted" style="position:absolute;bottom:8px;right:8px;z-index:2;pointer-events:none">Detecting color…</div>
        <div id="debugOverlay" class="color-indicator muted" style="position:absolute;bottom:36px;right:8px;z-index:2;pointer-events:none;font-size:11px;line-height:1.2"></div>
        <div id="roiHint" class="color-indicator muted" style="position:absolute;top:8px;left:8px;z-index:2;pointer-events:none;font-size:11px;background:rgba(0,0,0,0.35);color:white;padding:2px 6px;border-radius:6px">Tap the rash to focus detection</div>
      </div>

      <div class="stack" style="margin-top:12px">
        <input id="camera-input" class="hidden-input" type="file" accept="image/*" capture="environment" />
        <input id="gallery-input" class="hidden-input" type="file" accept="image/*" />
        <button class="btn primary full" id="btn-camera"><i class="bi bi-camera me-2"></i>Take Photo</button>
        <button class="btn outline full" id="btn-gallery"><i class="bi bi-upload me-2"></i>Upload from Gallery</button>
      </div>

      <!-- Controls shown only while camera is active -->
      <div id="camera-controls" class="row gap hidden" style="margin-top:12px">
        <button type="button" class="btn outline" id="btn-cancel-camera">Cancel</button>
        <button type="button" class="btn primary" id="btn-capture"><i class="bi bi-camera me-2"></i>Capture</button>
      </div>

      <div id="actions" class="row gap hidden" style="margin-top:12px">
        <button class="btn outline" id="btn-retake">Retake</button>
        <a class="btn primary" href="/bite-analysis-result" id="btn-analyze">Analyze Bite</a>
      </div>
    </div>

    <div class="card soft">
      <h3 class="card-title">Tips for Best Results</h3>
      <ul class="list small">
        <li>Ensure good lighting</li>
        <li>Keep the bite in focus</li>
        <li>Include surrounding skin for context</li>
        <li>Avoid blurry or dark images</li>
      </ul>
    </div>

    <script>
      const dz = document.getElementById('dropzone');
      const previewImg = document.getElementById('preview-img');
      const cameraInput = document.getElementById('camera-input');
      const galleryInput = document.getElementById('gallery-input');
      const btnCamera = document.getElementById('btn-camera');
      const btnGallery = document.getElementById('btn-gallery');
      const btnRetake = document.getElementById('btn-retake');
      const actions = document.getElementById('actions');
      const cameraVideo = document.getElementById('cameraVideo');
      const btnCapture = document.getElementById('btn-capture');
      const btnCancelCamera = document.getElementById('btn-cancel-camera');
      const cameraControls = document.getElementById('camera-controls');
      let mediaStream = null;
      let detectInterval = null;
      const detectCanvas = document.createElement('canvas');
      const detectCtx = detectCanvas.getContext('2d');
      const indicator = document.getElementById('colorIndicator');
      const debugOverlay = document.getElementById('debugOverlay');
      const roiHint = document.getElementById('roiHint');
      let roi = null; // { cx:0..1, cy:0..1, r:0..1 }

      function setIndicator(text, cls){
        if (!indicator) return;
        indicator.textContent = text;
        indicator.classList.remove('red','yellow','muted');
        if (cls) indicator.classList.add(cls); else indicator.classList.add('muted');
      }

      function setDebug(rFrac, yFrac, rFracC, yFracC){
        if (!debugOverlay) return;
        debugOverlay.textContent = `Global: R ${(rFrac*100).toFixed(1)}% | Y ${(yFrac*100).toFixed(1)}%  ·  ROI: R ${(rFracC*100).toFixed(1)}% | Y ${(yFracC*100).toFixed(1)}%`;
      }

      function rgbToHsv(r, g, b){
        const max = Math.max(r, g, b), min = Math.min(r, g, b);
        const d = max - min;
        let h = 0, s = max === 0 ? 0 : d / max, v = max;
        if (d !== 0){
          switch (max){
            case r: h = ((g - b) / d) % 6; break;
            case g: h = (b - r) / d + 2; break;
            case b: h = (r - g) / d + 4; break;
          }
          h *= 60; if (h < 0) h += 360;
        }
        return { h, s, v };
      }

      function analyzeImageData(data){
        // More robust detection:
        // - Broadened hue ranges
        // - Add RGB-dominance checks (r much higher than g/b for red; r&g high and b low for yellow)
        // - Track a central region to reduce background bias
        let red = 0, yellow = 0, total = 0;
        let redC = 0, yellowC = 0, centerTotal = 0;
        const arr = data.data;
        const w = data.width || 0, h = data.height || 0;
        // Default center box
        let cx0 = Math.floor(w * 0.20), cx1 = Math.ceil(w * 0.80);
        let cy0 = Math.floor(h * 0.20), cy1 = Math.ceil(h * 0.80);
        // If ROI set, convert normalized center/radius to box
        if (roi && typeof roi.cx === 'number' && typeof roi.cy === 'number'){
          const rc = Math.max(8, Math.floor(Math.min(w, h) * (roi.r || 0.25)));
          const cx = Math.floor((roi.cx || 0.5) * w);
          const cy = Math.floor((roi.cy || 0.5) * h);
          cx0 = Math.max(0, cx - rc); cx1 = Math.min(w - 1, cx + rc);
          cy0 = Math.max(0, cy - rc); cy1 = Math.min(h - 1, cy + rc);
        }

        for (let y = 0; y < h; y++){
          for (let x = 0; x < w; x++){
            const idx = (y * w + x) * 4;
            const r = arr[idx] / 255, g = arr[idx+1] / 255, b = arr[idx+2] / 255;

            const {h: hue, s, v} = rgbToHsv(r, g, b);
            // HSV conditions (wider ranges and slightly lower S/V cutoffs)
            const isRedHSV = (s >= 0.22 && v >= 0.18) && (hue <= 15 || hue >= 345);
            const isYellowHSV = (s >= 0.20 && v >= 0.25) && (hue >= 25 && hue <= 75);
            // RGB dominance conditions
            const maxGB = Math.max(g, b) + 1e-6;
            const isRedRGB = (r >= 0.35) && (r - Math.max(g, b) >= 0.10) && (r / (g + 1e-6) >= 1.30) && (r / (b + 1e-6) >= 1.30);
            const isYellowRGB = (r >= 0.30 && g >= 0.30 && b <= 0.45) && (Math.min(r, g) / Math.max(r, g) >= 0.75) && ((r - b) >= 0.08) && ((g - b) >= 0.08);
            // Pinkish: lower saturation reds with brighter value (common for rashes)
            const isPinkish = (v >= 0.6 && s >= 0.10 && s <= 0.40) && (hue <= 20 || hue >= 340) && (r > g && r > b);

            let isRed = isRedHSV || isRedRGB || isPinkish;
            // If a pixel qualifies as red, prefer red over yellow to avoid double counting
            let isYellow = !isRed && (isYellowHSV || isYellowRGB);

            if (isRed) red++; else if (isYellow) yellow++;
            total++;

            const inCenter = (x >= cx0 && x <= cx1 && y >= cy0 && y <= cy1);
            if (inCenter){
              centerTotal++;
              if (isRed) redC++; else if (isYellow) yellowC++;
            }
          }
        }
        return { red, yellow, total, redC, yellowC, centerTotal };
      }

      function decideLabel(stats){
        const { red, yellow, total, redC = 0, yellowC = 0, centerTotal = 0 } = stats;
        if (!total) return { text: 'No signal', cls: 'muted' };
        const rFrac = red / total, yFrac = yellow / total;
        const rFracC = centerTotal ? (redC / centerTotal) : 0;
        const yFracC = centerTotal ? (yellowC / centerTotal) : 0;
        // Lower global threshold and give more weight to the central region
        const minFrac = 0.005;        // 0.5% of all pixels
        const centerMinFrac = 0.01;   // 1% inside central ROI
        if ((rFrac >= minFrac && rFrac >= yFrac) || (rFracC >= centerMinFrac)){
          return { text: 'Detected: red/pink area', cls: 'red' };
        }
        if ((yFrac >= minFrac) || (yFracC >= centerMinFrac)){
          return { text: 'Detected: yellowish area', cls: 'yellow' };
        }
        return { text: 'No clear red/yellow detected', cls: 'muted' };
      }

      function startDetectionFromVideo(){
        if (!cameraVideo) return;
        stopDetection();
        setIndicator('Detecting color…', 'muted');
        detectInterval = setInterval(()=>{
          try {
            if (cameraVideo.readyState < 2) return;
            const w = 160, h = 120;
            detectCanvas.width = w; detectCanvas.height = h;
            detectCtx.drawImage(cameraVideo, 0, 0, w, h);
            const img = detectCtx.getImageData(0, 0, w, h);
            const stats = analyzeImageData(img);
            const res = decideLabel(stats);
            setIndicator(res.text, res.cls);
            const rFrac = stats.total ? stats.red / stats.total : 0;
            const yFrac = stats.total ? stats.yellow / stats.total : 0;
            const rFracC = stats.centerTotal ? stats.redC / stats.centerTotal : 0;
            const yFracC = stats.centerTotal ? stats.yellowC / stats.centerTotal : 0;
            setDebug(rFrac, yFrac, rFracC, yFracC);
          } catch(e) {}
        }, 400);
      }

      function stopDetection(){
        if (detectInterval){ clearInterval(detectInterval); detectInterval = null; }
      }

      function analyzeFromImage(el){
        try{
          const w = 200;
          const ratio = el.naturalWidth / el.naturalHeight;
          const h = Math.max(1, Math.round(w / (ratio || 1)));
          detectCanvas.width = w; detectCanvas.height = h;
          detectCtx.drawImage(el, 0, 0, w, h);
          const img = detectCtx.getImageData(0, 0, w, h);
          const stats = analyzeImageData(img);
          const res = decideLabel(stats);
          setIndicator(res.text, res.cls);
          const rFrac = stats.total ? stats.red / stats.total : 0;
          const yFrac = stats.total ? stats.yellow / stats.total : 0;
          const rFracC = stats.centerTotal ? stats.redC / stats.centerTotal : 0;
          const yFracC = stats.centerTotal ? stats.yellowC / stats.centerTotal : 0;
          setDebug(rFrac, yFrac, rFracC, yFracC);
        } catch(e) {}
      }
      function setStreamingUI(on){
        if (btnCamera) btnCamera.disabled = on;
        if (btnGallery) btnGallery.disabled = on;
        if (btnCapture) btnCapture.disabled = !on;
        if (btnCancelCamera) btnCancelCamera.disabled = !on;
      }

      function handleFile(file){
        if(!file) return;
        const reader = new FileReader();
        reader.onload = (ev)=>{
          previewImg.src = ev.target.result;
          previewImg.classList.remove('hidden');
          dz.classList.add('has-image');
          actions.classList.remove('hidden');
          stopDetection();
          // Wait a tick for the preview to render then analyze
          setTimeout(()=>analyzeFromImage(previewImg), 80);
        };
        reader.readAsDataURL(file);
      }

      async function openCamera(){
        try{
          // Immediately pause background and lock UI while we init camera
          try { if (window.__vantaDestroy) window.__vantaDestroy(); } catch(e){}
          setStreamingUI(true);
          if(!navigator.mediaDevices || !navigator.mediaDevices.getUserMedia){
            // Fallback to input with capture attr (mobile)
            cameraInput.click();
            setStreamingUI(false);
            return;
          }
          // Lower resolution and frame rate to reduce GPU/CPU load
          // Prefer the back camera; try exact environment first, then ideal, then deviceId fallback.
          const baseVideo = { width: { ideal: 960, max: 1280 }, height: { ideal: 540, max: 720 }, frameRate: { ideal: 15, max: 24 } };
          let pickedFacing = 'unknown';
          async function getStream(pref){
            return await navigator.mediaDevices.getUserMedia({ video: pref, audio: false });
          }
          try {
            mediaStream = await getStream({ ...baseVideo, facingMode: { exact: 'environment' } });
            pickedFacing = 'environment';
          } catch(err1) {
            try {
              mediaStream = await getStream({ ...baseVideo, facingMode: { ideal: 'environment' } });
              pickedFacing = 'environment';
            } catch(err2) {
              // Last resort: enumerate devices to find a likely back camera
              try {
                const devices = await navigator.mediaDevices.enumerateDevices();
                const vids = devices.filter(d => d.kind === 'videoinput');
                const back = vids.find(d => /back|rear|environment/i.test((d.label||''))) || vids.find(d => /front|user|face|integrated|built[- ]?in|webcam/i.test((d.label||''))) || vids[vids.length - 1];
                if (back) {
                  mediaStream = await getStream({ ...baseVideo, deviceId: { exact: back.deviceId } });
                  pickedFacing = /back|rear|environment/i.test((back.label||'')) ? 'environment' : (/front|user|face|integrated|built[- ]?in|webcam/i.test((back.label||'')) ? 'user' : 'unknown');
                } else {
                  // Fallback: let browser pick any camera
                  mediaStream = await getStream(baseVideo);
                }
              } catch(err3) {
                mediaStream = await getStream(baseVideo);
              }
            }
          }
          cameraVideo.srcObject = mediaStream;
          try { cameraVideo.play(); } catch(e){}
          // Auto mirror ONLY for front camera so movements feel natural
          try {
            const track = mediaStream.getVideoTracks()[0];
            const s = (track && track.getSettings) ? track.getSettings() : {};
            const c = (track && track.getCapabilities) ? track.getCapabilities() : {};
            const capFacing = (c && c.facingMode) ? c.facingMode : null;
            let label = (track && track.label ? track.label : '').toLowerCase();
            const facing = (s.facingMode || '').toLowerCase();
            let isFront = false;
            if (facing) {
              isFront = facing.includes('user') || facing.includes('front') || facing.includes('face');
            } else if (Array.isArray(capFacing) && capFacing.length) {
              isFront = capFacing.some(v => (v+'').toLowerCase().includes('user'));
            }
            // If still unknown, try to match deviceId to enumerated devices for a better label
            if (!isFront) {
              try {
                const devices = await navigator.mediaDevices.enumerateDevices();
                const vids = devices.filter(d => d.kind === 'videoinput');
                const active = vids.find(d => d.deviceId === s.deviceId);
                if (active && active.label) {
                  label = (active.label || '').toLowerCase();
                }
                if (!isFront && label) {
                  isFront = /front|user|face|webcam|integrated|built[- ]?in|internal/.test(label);
                }
                // If there is only one video input (common on laptops), assume front for natural preview
                if (!isFront && vids.length === 1) {
                  isFront = true;
                }
              } catch (e2) {}
            }
            // If still unknown, fall back to our earlier pick hint
            if (!isFront && pickedFacing === 'user') {
              isFront = true;
            }
            cameraVideo.style.transform = isFront ? 'scaleX(-1)' : '';
          } catch(e) {}
          // Show camera inline inside dropzone
          if (cameraVideo) cameraVideo.classList.remove('hidden');
          if (dz) dz.classList.add('camera-on');
          if (cameraControls) cameraControls.classList.remove('hidden');
          startDetectionFromVideo();
          // UI stays in streaming state
        }catch(err){
          // Permission denied or no camera => fallback
          try { cameraInput.click(); } catch(e){}
          setStreamingUI(false);
          // Resume background if we failed to open camera
          try { if (window.__vantaInit) setTimeout(()=>window.__vantaInit(), 50); } catch(e){}
        }
      }

      function stopStream(){
        if(mediaStream){
          mediaStream.getTracks().forEach(t=>t.stop());
          mediaStream = null;
        }
        setStreamingUI(false);
        stopDetection();
      }

      btnCamera.addEventListener('click',(e)=>{e.preventDefault(); openCamera();});
      btnGallery.addEventListener('click',(e)=>{e.preventDefault(); galleryInput.click();});

      cameraInput.addEventListener('change',(e)=>handleFile(e.target.files && e.target.files[0]));
      galleryInput.addEventListener('change',(e)=>handleFile(e.target.files && e.target.files[0]));

      // Tap-to-focus ROI on the preview image
      if (previewImg){
        previewImg.addEventListener('click', (ev)=>{
          if (!previewImg.naturalWidth || !previewImg.naturalHeight) return;
          const rect = previewImg.getBoundingClientRect();
          const cx = (ev.clientX - rect.left) / rect.width;
          const cy = (ev.clientY - rect.top) / rect.height;
          roi = { cx, cy, r: 0.25 };
          if (roiHint) roiHint.textContent = 'Tap again to move focus. Double-tap to reset.';
          analyzeFromImage(previewImg);
        });
        previewImg.addEventListener('dblclick', ()=>{
          roi = null;
          if (roiHint) roiHint.textContent = 'Tap the rash to focus detection';
          analyzeFromImage(previewImg);
        });
      }

      // Capture from live camera
      if (btnCapture){
        btnCapture.addEventListener('click',()=>{
          if(!mediaStream) return;
          const trackSettings = mediaStream.getVideoTracks()[0].getSettings();
          let w = trackSettings.width || 640;
          let h = trackSettings.height || 480;
          // Limit captured size for performance
          const maxW = 960;
          if (w > maxW) {
            const ratio = w / h;
            w = maxW; h = Math.round(maxW / ratio);
          }
          const canvas = document.createElement('canvas');
          canvas.width = w; canvas.height = h;
          const ctx = canvas.getContext('2d');
          ctx.drawImage(cameraVideo, 0, 0, w, h);
          canvas.toBlob((blob)=>{
            if(!blob) return;
            handleFile(new File([blob], 'capture.jpg', { type: 'image/jpeg' }));
            stopStream();
            // Hide camera element, show dropzone preview
            if (cameraVideo) cameraVideo.classList.add('hidden');
            if (dz) dz.classList.remove('camera-on');
            if (cameraControls) cameraControls.classList.add('hidden');
            // Resume background animation after closing
            try { if (window.__vantaInit) setTimeout(()=>window.__vantaInit(), 50); } catch(e){}
          }, 'image/jpeg', 0.92);
        });
      }

      // No manual flip control; preview is auto-corrected using facingMode

      // Cancel inline camera
      if (btnCancelCamera){
        btnCancelCamera.addEventListener('click', (e)=>{
          e.preventDefault();
          stopStream();
          if (cameraVideo) cameraVideo.classList.add('hidden');
          if (dz) dz.classList.remove('camera-on');
          if (cameraControls) cameraControls.classList.add('hidden');
          try { if (window.__vantaInit) setTimeout(()=>window.__vantaInit(), 50); } catch(e){}
        });
      }

      dz.addEventListener('dragover',(e)=>{e.preventDefault(); dz.classList.add('drag');});
      dz.addEventListener('dragleave',()=>dz.classList.remove('drag'));
      dz.addEventListener('drop',(e)=>{
        e.preventDefault(); dz.classList.remove('drag');
        const f = e.dataTransfer && e.dataTransfer.files && e.dataTransfer.files[0];
        handleFile(f);
      });

      btnRetake.addEventListener('click',(e)=>{
        e.preventDefault();
        previewImg.src='';
        previewImg.classList.add('hidden');
        dz.classList.remove('has-image');
        actions.classList.add('hidden');
        cameraInput.value=''; galleryInput.value='';
      });
    </script>
    <a class="btn linkback" href="/dashboard">← Back</a>
  {% endblock %}
