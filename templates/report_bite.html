{% extends 'base.html' %}
  {% block title %}Report a Bite - DengueTect{% endblock %}
  {% block content %}
    <h2 class="page-title">Report a Bite</h2>

    <div class="card soft">
      <h3 class="card-title">Upload Bite Photo</h3>
      <p class="muted">Take or upload a clear photo of the suspected mosquito bite for AI analysis</p>

      <div id="dropzone" class="dropzone" style="position:relative">
        <div class="dropzone-inner">
          <i class="bi bi-camera2 dropzone-icon"></i>
          <p class="muted">No image selected</p>
          <small class="muted">Drag & drop a photo here</small>
        </div>
        <img id="preview-img" class="dropzone-preview hidden" alt="Preview" />
        <!-- Inline camera lives inside the dropzone so no extra frame -->
        <video id="cameraVideo" class="dropzone-video hidden" autoplay playsinline muted></video>
        <div id="colorIndicator" class="color-indicator muted" style="position:absolute;bottom:8px;right:8px;z-index:2;pointer-events:none">Detecting color…</div>
        <div id="debugOverlay" class="color-indicator muted" style="position:absolute;bottom:36px;right:8px;z-index:2;pointer-events:none;font-size:11px;line-height:1.2"></div>
        <div id="roiHint" class="color-indicator muted" style="position:absolute;top:8px;left:8px;z-index:2;pointer-events:none;font-size:11px;background:rgba(0,0,0,0.35);color:white;padding:2px 6px;border-radius:6px">Tap the rash to focus detection</div>
        <div id="focusBox" class="focus-box"></div>
      </div>

      <div class="stack" style="margin-top:12px">
        <input id="camera-input" class="hidden-input" type="file" accept="image/*" capture="environment" />
        <input id="gallery-input" class="hidden-input" type="file" accept="image/*" />
        <button class="btn primary full" id="btn-camera"><i class="bi bi-camera me-2"></i>Take Photo</button>
        <button class="btn outline full" id="btn-gallery"><i class="bi bi-upload me-2"></i>Upload from Gallery</button>
      </div>

      <!-- Controls shown only while camera is active -->
      <div id="camera-controls" class="row gap hidden" style="margin-top:12px">
        <button type="button" class="btn outline" id="btn-cancel-camera">Cancel</button>
        <button type="button" class="btn primary" id="btn-capture"><i class="bi bi-camera me-2"></i>Capture</button>
      </div>

      <div id="actions" class="row gap hidden" style="margin-top:12px">
        <button class="btn outline" id="btn-retake">Retake</button>
        <a class="btn primary" href="/bite-analysis-result" id="btn-analyze" onclick="return window.__analyzeClick ? window.__analyzeClick(event) : true;">Analyze Bite</a>
      </div>
    </div>

    <div class="card soft">
      <h3 class="card-title">Tips for Best Results</h3>
      <ul class="list small">
        <li>Ensure good lighting</li>
        <li>Keep the bite in focus</li>
        <li>Include surrounding skin for context</li>
        <li>Avoid blurry or dark images</li>
      </ul>
    </div>

    <script>
      const dz = document.getElementById('dropzone');
      const previewImg = document.getElementById('preview-img');
      const cameraInput = document.getElementById('camera-input');
      const galleryInput = document.getElementById('gallery-input');
      const btnCamera = document.getElementById('btn-camera');
      const btnGallery = document.getElementById('btn-gallery');
      const btnRetake = document.getElementById('btn-retake');
      const actions = document.getElementById('actions');
      const cameraVideo = document.getElementById('cameraVideo');
      const btnCapture = document.getElementById('btn-capture');
      const btnCancelCamera = document.getElementById('btn-cancel-camera');
      const btnAnalyze = document.getElementById('btn-analyze');
      const cameraControls = document.getElementById('camera-controls');
      let mediaStream = null;
      let detectInterval = null;
      const detectCanvas = document.createElement('canvas');
      const detectCtx = detectCanvas.getContext('2d');
      const indicator = document.getElementById('colorIndicator');
      const debugOverlay = document.getElementById('debugOverlay');
      const roiHint = document.getElementById('roiHint');
      let roi = null; // { cx:0..1, cy:0..1, r:0..1 }
      const focusBox = document.getElementById('focusBox');
      let isFrontCamera = false;
      let _lastTapTs = 0, _lastTapX = 0, _lastTapY = 0;
      const ANALYSIS_KEY = 'biteAnalysis';
      let lastAnalysis = null; // { imageDataUrl, stats, res, ts }

      function setIndicator(text, cls){
        if (!indicator) return;
        indicator.textContent = text;
        indicator.classList.remove('red','yellow','muted');
        if (cls) indicator.classList.add(cls); else indicator.classList.add('muted');
      }

      function setDebug(rFrac, yFrac, rFracC, yFracC){
        if (!debugOverlay) return;
        debugOverlay.textContent = `Global: R ${(rFrac*100).toFixed(1)}% | Y ${(yFrac*100).toFixed(1)}%  ·  ROI: R ${(rFracC*100).toFixed(1)}% | Y ${(yFracC*100).toFixed(1)}%`;
      }

      // Helper: compress data URL for storage (limits to <=640px and JPEG quality)
      function compressDataUrlForStorage(url, maxDim=640, quality=0.85){
        return new Promise((resolve)=>{
          try{
            if (!url || typeof url !== 'string' || !url.startsWith('data:')){
              resolve(url); return;
            }
            const img = new Image();
            img.onload = function(){
              try{
                let w = img.naturalWidth || img.width || 0;
                let h = img.naturalHeight || img.height || 0;
                if (!w || !h){ resolve(url); return; }
                if (Math.max(w, h) > maxDim){
                  const r = w / h;
                  if (w >= h){ w = maxDim; h = Math.round(maxDim / (r || 1)); }
                  else { h = maxDim; w = Math.round(maxDim * (r || 1)); }
                }
                const c = document.createElement('canvas');
                c.width = w; c.height = h;
                const ctx = c.getContext('2d');
                ctx.drawImage(img, 0, 0, w, h);
                // Prefer JPEG to keep size small
                const out = c.toDataURL('image/jpeg', quality);
                resolve(out);
              }catch(e){ resolve(url); }
            };
            img.onerror = function(){ resolve(url); };
            img.src = url;
          }catch(e){ resolve(url); }
        });
      }

      // Build a JPEG blob suitable for upload by drawing onto a canvas (limits size)
      function makeBlobForUpload(url, maxDim=1024, quality=0.9){
        return new Promise((resolve)=>{
          try{
            if (!url || typeof url !== 'string') { resolve(null); return; }
            const img = new Image();
            img.onload = function(){
              try{
                let w = img.naturalWidth || img.width || 0;
                let h = img.naturalHeight || img.height || 0;
                if (!w || !h){ resolve(null); return; }
                if (Math.max(w, h) > maxDim){
                  const r = w / h;
                  if (w >= h){ w = maxDim; h = Math.round(maxDim / (r || 1)); }
                  else { h = maxDim; w = Math.round(maxDim * (r || 1)); }
                }
                const c = document.createElement('canvas');
                c.width = w; c.height = h;
                const ctx = c.getContext('2d');
                ctx.drawImage(img, 0, 0, w, h);
                c.toBlob((blob)=>{ resolve(blob); }, 'image/jpeg', quality);
              }catch(e){ resolve(null); }
            };
            img.onerror = function(){ resolve(null); };
            img.src = url;
          }catch(e){ resolve(null); }
        });
      }

      async function uploadToServer(imgUrl, roi, timeoutMs=6000){
        const blob = await makeBlobForUpload(imgUrl);
        if (!blob) return { ok:false };
        const fd = new FormData();
        fd.append('image', blob, 'upload.jpg');
        try{ fd.append('roi', JSON.stringify(roi||null)); }catch(_){ }
        function withTimeout(p, ms){
          return Promise.race([
            p,
            new Promise((resolve)=>setTimeout(()=>resolve({ __timeout:true, ok:false }), ms))
          ]);
        }
        const resp = await withTimeout(fetch('/api/analyze-bite', { method:'POST', body: fd }), timeoutMs);
        if (!resp || !resp.ok || resp.__timeout){ return { ok:false, __timeout: !!(resp && resp.__timeout) }; }
        const data = await resp.json().catch(()=>null);
        if (!data || !data.ok) return { ok:false };
        return { ok:true, data };
      }

      // Persist analysis to both sessionStorage (preferred) and localStorage (fallback)
      function saveAnalysisPayload(payload){
        try{ sessionStorage.setItem(ANALYSIS_KEY, JSON.stringify(payload)); }catch(_){ }
        try{ localStorage.setItem(ANALYSIS_KEY+':fallback', JSON.stringify(payload)); }catch(_){ }
      }

      function rgbToHsv(r, g, b){
        const max = Math.max(r, g, b), min = Math.min(r, g, b);
        const d = max - min;
        let h = 0, s = max === 0 ? 0 : d / max, v = max;
        if (d !== 0){
          switch (max){
            case r: h = ((g - b) / d) % 6; break;
            case g: h = (b - r) / d + 2; break;
            case b: h = (r - g) / d + 4; break;
          }
          h *= 60; if (h < 0) h += 360;
        }
        return { h, s, v };
      }

      function analyzeImageData(data){
        // More robust detection:
        // - Broadened hue ranges
        // - Add RGB-dominance checks (r much higher than g/b for red; r&g high and b low for yellow)
        // - Track a central region to reduce background bias
        let red = 0, yellow = 0, total = 0;
        let redC = 0, yellowC = 0, centerTotal = 0;
        let strongRed = 0, strongRedC = 0;
        const arr = data.data;
        const w = data.width || 0, h = data.height || 0;
        // Default center box
        let cx0 = Math.floor(w * 0.20), cx1 = Math.ceil(w * 0.80);
        let cy0 = Math.floor(h * 0.20), cy1 = Math.ceil(h * 0.80);
        // If ROI set, convert normalized center/radius to box
        if (roi && typeof roi.cx === 'number' && typeof roi.cy === 'number'){
          const rc = Math.max(8, Math.floor(Math.min(w, h) * (roi.r || 0.25)));
          const cx = Math.floor((roi.cx || 0.5) * w);
          const cy = Math.floor((roi.cy || 0.5) * h);
          cx0 = Math.max(0, cx - rc); cx1 = Math.min(w - 1, cx + rc);
          cy0 = Math.max(0, cy - rc); cy1 = Math.min(h - 1, cy + rc);
        }

        // Coarse tiling to estimate local cluster density (helps avoid noise)
        const gx = 16, gy = 12; // for 160x120 downsample, tiles are ~10x10 px
        const cellW = Math.max(1, Math.floor(w / gx));
        const cellH = Math.max(1, Math.floor(h / gy));
        const tileR = new Array(gx * gy).fill(0);
        const tileY = new Array(gx * gy).fill(0);
        const tileT = new Array(gx * gy).fill(0);

        for (let y = 0; y < h; y++){
          for (let x = 0; x < w; x++){
            const idx = (y * w + x) * 4;
            const r = arr[idx] / 255, g = arr[idx+1] / 255, b = arr[idx+2] / 255;

            const {h: hue, s, v} = rgbToHsv(r, g, b);
            // Discard dark/low-saturation pixels early (avoid shadows/gray noise)
            // Do NOT include them in the denominator so true signals aren't diluted
            if (v < 0.25 || s < 0.18){ continue; }

            // Stricter HSV gating (slightly relaxed to allow vivid pen/marker)
            const isRedHSV = (s >= 0.24 && v >= 0.30) && (hue <= 15 || hue >= 345);
            const isYellowHSV = (s >= 0.22 && v >= 0.45) && (hue >= 35 && hue <= 70);
            // Strong RGB dominance constraints (slightly relaxed)
            const isRedRGB = (r >= 0.45) && (r - Math.max(g, b) >= 0.15) && (r / (g + 1e-6) >= 1.25) && (r / (b + 1e-6) >= 1.30);
            const isYellowRGB = (r >= 0.42 && g >= 0.42 && b <= 0.38) && (Math.min(r, g) / Math.max(r, g) >= 0.78) && ((r - b) >= 0.10) && ((g - b) >= 0.10);
            // Very strong-red override for marker/pen
            const isStrongRed = (r >= 0.65 && g <= 0.35 && b <= 0.35) && ((r - Math.max(g,b)) >= 0.18);

            // Require BOTH HSV and RGB; allow strong-red override
            let isRed = (isRedHSV && isRedRGB) || isStrongRed;
            const isYellow = !isRed && (isYellowHSV && isYellowRGB);

            if (isRed) red++; else if (isYellow) yellow++;
            total++;

            const inCenter = (x >= cx0 && x <= cx1 && y >= cy0 && y <= cy1);
            if (inCenter){
              centerTotal++;
              if (isRed) {
                redC++;
                if (isStrongRed) strongRedC++;
              } else if (isYellow) {
                yellowC++;
              }
            }

            // Accumulate coarse tile stats to gauge cluster density
            const tx = Math.min(gx - 1, Math.floor(x / cellW));
            const ty = Math.min(gy - 1, Math.floor(y / cellH));
            const ti = ty * gx + tx;
            tileT[ti]++;
            if (isRed) tileR[ti]++; else if (isYellow) tileY[ti]++;
            if (isStrongRed) strongRed++;
          }
        }
        // Compute strongest local density per color
        let tileMaxRedDensity = 0, tileMaxYellowDensity = 0;
        for (let i = 0; i < tileT.length; i++){
          const t = tileT[i] || 0;
          if (!t) continue;
          tileMaxRedDensity = Math.max(tileMaxRedDensity, (tileR[i] || 0) / t);
          tileMaxYellowDensity = Math.max(tileMaxYellowDensity, (tileY[i] || 0) / t);
        }
        return { red, yellow, total, redC, yellowC, centerTotal, tileMaxRedDensity, tileMaxYellowDensity, strongRed, strongRedC };
      }

      function decideLabel(stats){
        const { red, yellow, total, redC = 0, yellowC = 0, centerTotal = 0, tileMaxRedDensity = 0, tileMaxYellowDensity = 0, strongRed = 0, strongRedC = 0 } = stats;
        if (!total) return { text: 'No signal', cls: 'muted' };
        const rFrac = red / total, yFrac = yellow / total;
        const rFracC = centerTotal ? (redC / centerTotal) : 0;
        const yFracC = centerTotal ? (yellowC / centerTotal) : 0;
        const roiPresent = !!(roi && typeof roi.cx === 'number');
        // ROI-aware thresholds: more lenient if user set an ROI (double-tap/tap)
        const minFracGlobal = roiPresent ? 0.008 : 0.02;  // 0.8% vs 2%
        const minFracROI    = roiPresent ? 0.015 : 0.05;  // 1.5% vs 5%
        const minTileDensity= roiPresent ? 0.05 : 0.10;  // 5% vs 10%
        // Strong red overrides
        const strongRedOK = roiPresent && strongRedC >= Math.max(8, centerTotal * 0.005);
        const strongRedGlobalOK = !roiPresent && (strongRed >= Math.max(20, total * 0.0025)) && (tileMaxRedDensity >= 0.06);

        const redOK = strongRedOK || strongRedGlobalOK || (((rFrac >= minFracGlobal) || (rFracC >= minFracROI)) && (tileMaxRedDensity >= minTileDensity) && (rFrac >= yFrac * 1.05));
        const yellowOK = !redOK && (((yFrac >= minFracGlobal) || (yFracC >= minFracROI)) && (tileMaxYellowDensity >= minTileDensity));

        if (redOK) return { text: 'Detected: red/pink area', cls: 'red' };
        if (yellowOK) return { text: 'Detected: yellowish area', cls: 'yellow' };
        return { text: 'No clear red/yellow detected', cls: 'muted' };
      }

      function startDetectionFromVideo(){
        if (!cameraVideo) return;
        stopDetection();
        setIndicator('Detecting color…', 'muted');
        detectInterval = setInterval(()=>{
          try {
            if (cameraVideo.readyState < 2) return;
            const w = 160, h = 120;
            detectCanvas.width = w; detectCanvas.height = h;
            detectCtx.drawImage(cameraVideo, 0, 0, w, h);
            const img = detectCtx.getImageData(0, 0, w, h);
            const stats = analyzeImageData(img);
            const res = decideLabel(stats);
            setIndicator(res.text, res.cls);
            const rFrac = stats.total ? stats.red / stats.total : 0;
            const yFrac = stats.total ? stats.yellow / stats.total : 0;
            const rFracC = stats.centerTotal ? stats.redC / stats.centerTotal : 0;
            const yFracC = stats.centerTotal ? stats.yellowC / stats.centerTotal : 0;
            setDebug(rFrac, yFrac, rFracC, yFracC);
          } catch(e) {}
        }, 400);
      }

      function stopDetection(){
        if (detectInterval){ clearInterval(detectInterval); detectInterval = null; }
      }

      function analyzeFromImage(el){
        try{
          const w = 200;
          const ratio = el.naturalWidth / el.naturalHeight;
          const h = Math.max(1, Math.round(w / (ratio || 1)));
          detectCanvas.width = w; detectCanvas.height = h;
          detectCtx.drawImage(el, 0, 0, w, h);
          const img = detectCtx.getImageData(0, 0, w, h);
          const stats = analyzeImageData(img);
          const res = decideLabel(stats);
          setIndicator(res.text, res.cls);
          const rFrac = stats.total ? stats.red / stats.total : 0;
          const yFrac = stats.total ? stats.yellow / stats.total : 0;
          const rFracC = stats.centerTotal ? stats.redC / stats.centerTotal : 0;
          const yFracC = stats.centerTotal ? stats.yellowC / stats.centerTotal : 0;
          setDebug(rFrac, yFrac, rFracC, yFracC);
          // Keep latest analysis snapshot
          lastAnalysis = {
            imageDataUrl: (el && el.src) ? el.src : (previewImg && previewImg.src) ? previewImg.src : '',
            stats, res, ts: Date.now(), roi
          };
          // Persist immediately as a safety net (without large image to avoid quota)
          try{
            const autoPayload = {
              imageDataUrl: '',
              imageUrl: '',
              labelText: res && res.text || '',
              labelCls: res && res.cls || '',
              stats,
              roi,
              ts: Date.now(),
              source: 'client:auto'
            };
            saveAnalysisPayload(autoPayload);
          }catch(_){ }
        } catch(e) {}
      }
      function setStreamingUI(on){
        if (btnCamera) btnCamera.disabled = on;
        if (btnGallery) btnGallery.disabled = on;
        if (btnCapture) btnCapture.disabled = !on;
        if (btnCancelCamera) btnCancelCamera.disabled = !on;
      }

      function handleFile(file){
        if(!file) return;
        const reader = new FileReader();
        reader.onload = (ev)=>{
          previewImg.src = ev.target.result;
          previewImg.classList.remove('hidden');
          dz.classList.add('has-image');
          actions.classList.remove('hidden');
          stopDetection();
          // Wait a tick for the preview to render then analyze
          setTimeout(()=>analyzeFromImage(previewImg), 80);
        };
        reader.readAsDataURL(file);
      }

      async function openCamera(){
        try{
          // Immediately pause background and lock UI while we init camera
          try { if (window.__vantaDestroy) window.__vantaDestroy(); } catch(e){}
          setStreamingUI(true);
          if(!navigator.mediaDevices || !navigator.mediaDevices.getUserMedia){
            // Fallback to input with capture attr (mobile)
            cameraInput.click();
            setStreamingUI(false);
            return;
          }
          // Lower resolution and frame rate to reduce GPU/CPU load
          // Prefer the back camera; try exact environment first, then ideal, then deviceId fallback.
          const baseVideo = { width: { ideal: 960, max: 1280 }, height: { ideal: 540, max: 720 }, frameRate: { ideal: 15, max: 24 } };
          let pickedFacing = 'unknown';
          async function getStream(pref){
            return await navigator.mediaDevices.getUserMedia({ video: pref, audio: false });
          }
          try {
            mediaStream = await getStream({ ...baseVideo, facingMode: { exact: 'environment' } });
            pickedFacing = 'environment';
          } catch(err1) {
            try {
              mediaStream = await getStream({ ...baseVideo, facingMode: { ideal: 'environment' } });
              pickedFacing = 'environment';
            } catch(err2) {
              // Last resort: enumerate devices to find a likely back camera
              try {
                const devices = await navigator.mediaDevices.enumerateDevices();
                const vids = devices.filter(d => d.kind === 'videoinput');
                const back = vids.find(d => /back|rear|environment/i.test((d.label||''))) || vids.find(d => /front|user|face|integrated|built[- ]?in|webcam/i.test((d.label||''))) || vids[vids.length - 1];
                if (back) {
                  mediaStream = await getStream({ ...baseVideo, deviceId: { exact: back.deviceId } });
                  pickedFacing = /back|rear|environment/i.test((back.label||'')) ? 'environment' : (/front|user|face|integrated|built[- ]?in|webcam/i.test((back.label||'')) ? 'user' : 'unknown');
                } else {
                  // Fallback: let browser pick any camera
                  mediaStream = await getStream(baseVideo);
                }
              } catch(err3) {
                mediaStream = await getStream(baseVideo);
              }
            }
          }
          cameraVideo.srcObject = mediaStream;
          try { cameraVideo.play(); } catch(e){}
          // Auto mirror ONLY for front camera so movements feel natural
          try {
            const track = mediaStream.getVideoTracks()[0];
            const s = (track && track.getSettings) ? track.getSettings() : {};
            const c = (track && track.getCapabilities) ? track.getCapabilities() : {};
            const capFacing = (c && c.facingMode) ? c.facingMode : null;
            let label = (track && track.label ? track.label : '').toLowerCase();
            const facing = (s.facingMode || '').toLowerCase();
            let isFront = false;
            if (facing) {
              isFront = facing.includes('user') || facing.includes('front') || facing.includes('face');
            } else if (Array.isArray(capFacing) && capFacing.length) {
              isFront = capFacing.some(v => (v+'').toLowerCase().includes('user'));
            }
            // If still unknown, try to match deviceId to enumerated devices for a better label
            if (!isFront) {
              try {
                const devices = await navigator.mediaDevices.enumerateDevices();
                const vids = devices.filter(d => d.kind === 'videoinput');
                const active = vids.find(d => d.deviceId === s.deviceId);
                if (active && active.label) {
                  label = (active.label || '').toLowerCase();
                }
                if (!isFront && label) {
                  isFront = /front|user|face|webcam|integrated|built[- ]?in|internal/.test(label);
                }
                // If there is only one video input (common on laptops), assume front for natural preview
                if (!isFront && vids.length === 1) {
                  isFront = true;
                }
              } catch (e2) {}
            }
            // If still unknown, fall back to our earlier pick hint
            if (!isFront && pickedFacing === 'user') {
              isFront = true;
            }
            cameraVideo.style.transform = isFront ? 'scaleX(-1)' : '';
            isFrontCamera = isFront;
          } catch(e) {}
          // Show camera inline inside dropzone
          if (cameraVideo) cameraVideo.classList.remove('hidden');
          if (dz) dz.classList.add('camera-on');
          if (cameraControls) cameraControls.classList.remove('hidden');
          startDetectionFromVideo();
          // UI stays in streaming state
        }catch(err){
          // Permission denied or no camera => fallback
          try { cameraInput.click(); } catch(e){}
          setStreamingUI(false);
          // Resume background if we failed to open camera
          try { if (window.__vantaInit) setTimeout(()=>window.__vantaInit(), 50); } catch(e){}
        }
      }

      function stopStream(){
        if(mediaStream){
          mediaStream.getTracks().forEach(t=>t.stop());
          mediaStream = null;
        }
        setStreamingUI(false);
        stopDetection();
      }

      btnCamera.addEventListener('click',(e)=>{e.preventDefault(); openCamera();});
      btnGallery.addEventListener('click',(e)=>{e.preventDefault(); galleryInput.click();});

      cameraInput.addEventListener('change',(e)=>handleFile(e.target.files && e.target.files[0]));
      galleryInput.addEventListener('change',(e)=>handleFile(e.target.files && e.target.files[0]));

      // Helper: show animated focus box at a client position
      function showFocusAt(clientX, clientY){
        if (!focusBox || !dz) return;
        const drect = dz.getBoundingClientRect();
        focusBox.style.left = (clientX - drect.left) + 'px';
        focusBox.style.top = (clientY - drect.top) + 'px';
        focusBox.classList.remove('show');
        void focusBox.offsetWidth; // reflow to restart animation
        focusBox.classList.add('show');
      }

      // Double-tap to focus for live camera preview
      function handleTapFor(el){
        if (!el) return;
        const onTap = (ev)=>{
          const now = Date.now();
          const dt = now - _lastTapTs;
          const isDouble = dt > 0 && dt < 350; // within 350ms
          _lastTapTs = now; _lastTapX = ev.clientX; _lastTapY = ev.clientY;
          if (!isDouble) return;
          const rect = el.getBoundingClientRect();
          if (!rect.width || !rect.height) return;
          let nx = (ev.clientX - rect.left) / rect.width; // 0..1
          let ny = (ev.clientY - rect.top) / rect.height; // 0..1
          nx = Math.max(0, Math.min(1, nx));
          ny = Math.max(0, Math.min(1, ny));
          // Mirror X if front camera preview is mirrored with CSS
          const cx = isFrontCamera ? (1 - nx) : nx;
          const cy = ny;
          roi = { cx, cy, r: 0.25 };
          if (roiHint) roiHint.textContent = 'Focus set (double-tap to move)';
          showFocusAt(ev.clientX, ev.clientY);
        };
        // Pointer events (modern)
        el.addEventListener('pointerdown', onTap);
        // iOS Safari fallback
        el.addEventListener('touchstart', function(te){
          try{
            if (te.touches && te.touches[0]){
              const t = te.touches[0];
              onTap({ clientX: t.clientX, clientY: t.clientY });
            }
          }catch(e){}
        }, { passive: true });
      }

      handleTapFor(cameraVideo);

      // Tap-to-focus ROI on the preview image
      if (previewImg){
        previewImg.addEventListener('click', (ev)=>{
          if (!previewImg.naturalWidth || !previewImg.naturalHeight) return;
          const rect = previewImg.getBoundingClientRect();
          const cx = (ev.clientX - rect.left) / rect.width;
          const cy = (ev.clientY - rect.top) / rect.height;
          roi = { cx, cy, r: 0.25 };
          if (roiHint) roiHint.textContent = 'Tap again to move focus. Double-tap to reset.';
          showFocusAt(ev.clientX, ev.clientY);
          analyzeFromImage(previewImg);
        });
        previewImg.addEventListener('dblclick', ()=>{
          roi = null;
          if (roiHint) roiHint.textContent = 'Tap the rash to focus detection';
          analyzeFromImage(previewImg);
        });
      }

      // Capture from live camera
      if (btnCapture){
        btnCapture.addEventListener('click',()=>{
          if(!mediaStream) return;
          const trackSettings = mediaStream.getVideoTracks()[0].getSettings();
          let w = trackSettings.width || 640;
          let h = trackSettings.height || 480;
          // Limit captured size for performance
          const maxW = 960;
          if (w > maxW) {
            const ratio = w / h;
            w = maxW; h = Math.round(maxW / ratio);
          }
          const canvas = document.createElement('canvas');
          canvas.width = w; canvas.height = h;
          const ctx = canvas.getContext('2d');
          ctx.drawImage(cameraVideo, 0, 0, w, h);
          canvas.toBlob((blob)=>{
            if(!blob) return;
            handleFile(new File([blob], 'capture.jpg', { type: 'image/jpeg' }));
            stopStream();
            // Hide camera element, show dropzone preview
            if (cameraVideo) cameraVideo.classList.add('hidden');
            if (dz) dz.classList.remove('camera-on');
            if (cameraControls) cameraControls.classList.add('hidden');
            // Resume background animation after closing
            try { if (window.__vantaInit) setTimeout(()=>window.__vantaInit(), 50); } catch(e){}
          }, 'image/jpeg', 0.92);
        });
      }

      // No manual flip control; preview is auto-corrected using facingMode

      // Cancel inline camera
      if (btnCancelCamera){
        btnCancelCamera.addEventListener('click', (e)=>{
          e.preventDefault();
          stopStream();
          if (cameraVideo) cameraVideo.classList.add('hidden');
          if (dz) dz.classList.remove('camera-on');
          if (cameraControls) cameraControls.classList.add('hidden');
          try { if (window.__vantaInit) setTimeout(()=>window.__vantaInit(), 50); } catch(e){}
        });
      }

      dz.addEventListener('dragover',(e)=>{e.preventDefault(); dz.classList.add('drag');});
      dz.addEventListener('dragleave',()=>dz.classList.remove('drag'));
      dz.addEventListener('drop',(e)=>{
        e.preventDefault(); dz.classList.remove('drag');
        const f = e.dataTransfer && e.dataTransfer.files && e.dataTransfer.files[0];
        handleFile(f);
      });

      btnRetake.addEventListener('click',(e)=>{
        e.preventDefault();
        previewImg.src='';
        previewImg.classList.add('hidden');
        dz.classList.remove('has-image');
        actions.classList.add('hidden');
        cameraInput.value=''; galleryInput.value='';
        lastAnalysis = null;
      });

      // Persist and navigate to result page on Analyze
      async function __handleAnalyzeClick(e){
          e.preventDefault();
          const href = e.currentTarget.getAttribute('href') || '/bite-analysis-result';
          let navigateUrl = href;
          btnAnalyze.disabled = true;
          const origLabel = btnAnalyze.textContent;
          try{ btnAnalyze.textContent = 'Analyzing…'; }catch(_){ }
          try{
            if (!lastAnalysis && previewImg && previewImg.src){
              analyzeFromImage(previewImg);
            }
            let payload = null;
            const imgUrl = (previewImg && previewImg.src) || (lastAnalysis && lastAnalysis.imageDataUrl) || '';
            if (lastAnalysis){
              const storageImg2 = await compressDataUrlForStorage(lastAnalysis.imageDataUrl || '');
              payload = {
                imageDataUrl: storageImg2,
                imageUrl: '',
                labelText: lastAnalysis.res && lastAnalysis.res.text || indicator.textContent || '',
                labelCls: lastAnalysis.res && lastAnalysis.res.cls || '',
                stats: lastAnalysis.stats || null,
                roi: lastAnalysis.roi || roi || null,
                ts: Date.now(),
                source: 'client'
              };
            }
            // Ensure at least a minimal payload exists (with image) before server call
            if (!payload && imgUrl){
              try{
                const storageImgMin = await compressDataUrlForStorage(imgUrl);
                payload = {
                  imageDataUrl: storageImgMin,
                  imageUrl: '',
                  labelText: (indicator && indicator.textContent) || 'Analysis pending',
                  labelCls: (indicator && (indicator.classList.contains('red') ? 'red' : indicator.classList.contains('yellow') ? 'yellow' : 'muted')) || 'muted',
                  stats: null,
                  roi: roi || null,
                  ts: Date.now(),
                  source: 'client:min'
                };
                saveAnalysisPayload(payload);
              }catch(_){ }
            }
            if (imgUrl){
              try{
                const serverResp = await uploadToServer(imgUrl, roi, 6000);
                if (serverResp && serverResp.ok && serverResp.data){
                  const d = serverResp.data;
                  const serverPayload = {
                    imageDataUrl: '',
                    imageUrl: d.image_url || '',
                    labelText: d.labelText || '',
                    labelCls: d.labelCls || '',
                    stats: d.stats || null,
                    roi: d.roi || roi || null,
                    ts: Date.now(),
                    source: 'server',
                    analysisId: d.analysis_id || ''
                  };
                  saveAnalysisPayload(serverPayload);
                  if (d.analysis_id){
                    navigateUrl = href + (href.includes('?') ? '&' : '?') + 'aid=' + encodeURIComponent(d.analysis_id);
                  }
                }
              }catch(_){ }
            }
          }catch(_){ }
          // Store client payload if we have one
          try{ if (payload) saveAnalysisPayload(payload); }catch(_){ }
          // Navigate regardless
          window.location.href = navigateUrl;
          try{ btnAnalyze.textContent = origLabel; }catch(_){ }
          return false;
      }
      window.__analyzeClick = __handleAnalyzeClick;
      if (btnAnalyze){ btnAnalyze.addEventListener('click', __handleAnalyzeClick); }
    </script>
    <a class="btn linkback" href="/dashboard">← Back</a>
  {% endblock %}
